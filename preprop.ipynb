{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      positivity sentiment relevance  \\\n",
      "0            3.0  negative       yes   \n",
      "4            3.0  negative       yes   \n",
      "5            3.0  negative       yes   \n",
      "9            4.0   neutral       yes   \n",
      "12           4.0   neutral       yes   \n",
      "...          ...       ...       ...   \n",
      "7973         7.0  positive       yes   \n",
      "7974         3.0  negative       yes   \n",
      "7984         8.0  positive       yes   \n",
      "7987         5.0   neutral       yes   \n",
      "7995         7.0  positive       yes   \n",
      "\n",
      "                                               headline  \\\n",
      "0                 Yields on CDs Fell in the Latest Week   \n",
      "4     Currency Trading: Dollar Remains in Tight Rang...   \n",
      "5                  Stocks Fall Again; BofA, Alcoa Slide   \n",
      "9     U.S. Dollar Falls Against Most Currencies; Dec...   \n",
      "12                 Defending Yourself Against Deflation   \n",
      "...                                                 ...   \n",
      "7973  Housing Starts Grow, Raising Inflation Fears: ...   \n",
      "7974  Profits Often Evasive In Stock Mart Rallies Gr...   \n",
      "7984          Salomon Sounds a Wary Note on the Economy   \n",
      "7987  The Great Terror; A massive new history of Hit...   \n",
      "7995  Sawyer Sees Strong Economy For 2 Years, Truce ...   \n",
      "\n",
      "                                                   text  \n",
      "0     NEW YORK -- Yields on most certificates of dep...  \n",
      "4     NEW YORK -- Indecision marked the dollar's ton...  \n",
      "5     Stocks declined, as investors weighed slower-t...  \n",
      "9     The U.S. dollar declined against most major fo...  \n",
      "12    Author: James B. Stewart</br></br>The dreaded ...  \n",
      "...                                                 ...  \n",
      "7973  Housing starts surged by 4.4 percent last mont...  \n",
      "7974  When it comes to actually cashing in, stock ma...  \n",
      "7984  Perhaps nothing about the Clinton administrati...  \n",
      "7987  Looking at the enormous -- and incessant -- ti...  \n",
      "7995  Secretary of Commerce Charles W. Sawyer said y...  \n",
      "\n",
      "[1420 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('Full-Economic-News-DFE-839861.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 1: Keep only the relevant columns\n",
    "df = df[['positivity', 'relevance', 'headline', 'text']]\n",
    "\n",
    "# Step 2: Drop rows where any of the relevant columns have NaN or empty values\n",
    "df_cleaned = df.dropna(subset=['positivity', 'relevance', 'headline', 'text'])\n",
    "\n",
    "# Optionally, remove any rows where the text column is empty or contains only whitespace\n",
    "df_cleaned = df_cleaned[df_cleaned['text'].str.strip().astype(bool)]\n",
    "\n",
    "# Step 3: Create a new column 'sentiment' based on the positivity score\n",
    "def categorize_sentiment(positivity):\n",
    "    if 1 <= positivity <= 3:\n",
    "        return 'negative'\n",
    "    elif 4 <= positivity <= 6:\n",
    "        return 'neutral'\n",
    "    elif 7 <= positivity <= 9:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return None  # In case there are out-of-range values\n",
    "\n",
    "df_cleaned['sentiment'] = df_cleaned['positivity'].apply(categorize_sentiment)\n",
    "\n",
    "# Display the cleaned and categorized DataFrame\n",
    "print(df_cleaned[['positivity', 'sentiment', 'relevance', 'headline', 'text']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               headline  \\\n",
      "0                 Yields on CDs Fell in the Latest Week   \n",
      "4     Currency Trading: Dollar Remains in Tight Rang...   \n",
      "5                  Stocks Fall Again; BofA, Alcoa Slide   \n",
      "9     U.S. Dollar Falls Against Most Currencies; Dec...   \n",
      "12                 Defending Yourself Against Deflation   \n",
      "...                                                 ...   \n",
      "7973  Housing Starts Grow, Raising Inflation Fears: ...   \n",
      "7974  Profits Often Evasive In Stock Mart Rallies Gr...   \n",
      "7984          Salomon Sounds a Wary Note on the Economy   \n",
      "7987  The Great Terror; A massive new history of Hit...   \n",
      "7995  Sawyer Sees Strong Economy For 2 Years, Truce ...   \n",
      "\n",
      "                                     tokenized_headline  \n",
      "0        [Yields, on, CDs, Fell, in, the, Latest, Week]  \n",
      "4     [Currency, Trading, :, Dollar, Remains, in, Ti...  \n",
      "5       [Stocks, Fall, Again, ;, BofA, ,, Alcoa, Slide]  \n",
      "9     [U.S., Dollar, Falls, Against, Most, Currencie...  \n",
      "12            [Defending, Yourself, Against, Deflation]  \n",
      "...                                                 ...  \n",
      "7973  [Housing, Starts, Grow, ,, Raising, Inflation,...  \n",
      "7974  [Profits, Often, Evasive, In, Stock, Mart, Ral...  \n",
      "7984  [Salomon, Sounds, a, Wary, Note, on, the, Econ...  \n",
      "7987  [The, Great, Terror, ;, A, massive, new, histo...  \n",
      "7995  [Sawyer, Sees, Strong, Economy, For, 2, Years,...  \n",
      "\n",
      "[1420 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dhritigampa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download nltk's punkt tokenizer if you haven't already\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def func(string):\n",
    "    return string\n",
    "\n",
    "# Tokenize each headline in the dataframe\n",
    "df_cleaned['tokenized_headline'] = df_cleaned['headline'].apply(word_tokenize)\n",
    "\n",
    "print(df_cleaned[['headline', 'tokenized_headline']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train a Word2Vec model on tokenized headlines\n",
    "model = Word2Vec(sentences=df_cleaned['tokenized_headline'], vector_size=100, window=5, min_count=2, sg=1)\n",
    "\n",
    "# Step 5: Generate embeddings for each headline by averaging word vectors\n",
    "def get_headline_vector(tokens, model):\n",
    "    # Filter out words not in the vocabulary and calculate the mean of word vectors\n",
    "    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df_cleaned['headline_vector'] = df_cleaned['tokenized_headline'].apply(lambda tokens: get_headline_vector(tokens, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Prepare data for the classifier\n",
    "X = np.vstack(df_cleaned['headline_vector'].values)  # Stack vectors into a 2D array\n",
    "y = df_cleaned['sentiment']  # Target labels\n",
    "\n",
    "# Step 7: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.14      0.20        72\n",
      "     neutral       0.50      0.84      0.63       142\n",
      "    positive       0.50      0.14      0.22        70\n",
      "\n",
      "    accuracy                           0.49       284\n",
      "   macro avg       0.45      0.37      0.35       284\n",
      "weighted avg       0.47      0.49      0.42       284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Step 10: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
